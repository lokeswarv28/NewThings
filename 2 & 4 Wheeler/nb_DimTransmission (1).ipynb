{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fe2b275-e128-4205-b819-6ae92dbf2386",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the path to your Parquet files\n",
    "# parquet_file_path1 = \"dbfs:/Silver/2024/month=03/date=2024-03-15/df1_20240315_132137.parquet\"\n",
    "parquet_file_path1 = \"dbfs:/Silver/2_wheelers/202403/29/*.parquet\"\n",
    "parquet_file_path2 = \"dbfs:/Silver/4_wheelers/202403/29/*.parquet\"\n",
    "\n",
    "# Read the Parquet file into a DataFrame\n",
    "# df1 = spark.read.parquet(parquet_file_path1)\n",
    "# display(df1)\n",
    "# df2= spark.read.parquet(parquet_file_path2)\n",
    "# display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78804a46-759b-4efa-bac5-f8a515e42568",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_count : 91440\ncombined_distinct : 91440\n+------------+----------+\n|Transmission|wheelerkey|\n+------------+----------+\n|   Automatic|         F|\n|   Automatic|         F|\n|      Manual|         F|\n|   Automatic|         F|\n|   Automatic|         F|\n|   Automatic|         F|\n|   Automatic|         F|\n|      Manual|         F|\n|   Automatic|         F|\n|   Automatic|         F|\n|      Manual|         F|\n|   Automatic|         F|\n|   Automatic|         F|\n|   Automatic|         F|\n|   Automatic|         F|\n|      Manual|         F|\n|   Automatic|         F|\n|   Automatic|         F|\n|      Manual|         F|\n|   Automatic|         F|\n+------------+----------+\nonly showing top 20 rows\n\ndim_df show...\n+----------------+------------+----------+\n|pkTransmissionId|Transmission|WheelerKey|\n+----------------+------------+----------+\n+----------------+------------+----------+\n\ncheck for new records...\n+------------+----------+\n|Transmission|wheelerkey|\n+------------+----------+\n|   Automatic|         F|\n|   Automatic|         F|\n|      Manual|         F|\n|   Automatic|         F|\n|   Automatic|         F|\n|   Automatic|         F|\n|   Automatic|         F|\n|      Manual|         F|\n|   Automatic|         F|\n|   Automatic|         F|\n|      Manual|         F|\n|   Automatic|         F|\n|   Automatic|         F|\n|   Automatic|         F|\n|   Automatic|         F|\n|      Manual|         F|\n|   Automatic|         F|\n|   Automatic|         F|\n|      Manual|         F|\n|   Automatic|         F|\n+------------+----------+\nonly showing top 20 rows\n\nmatching from src to target \n+----------------+------------+----------+\n|pkTransmissionId|Transmission|WheelerKey|\n+----------------+------------+----------+\n+----------------+------------+----------+\n\ncombined....\ncombined_records df count: 2\n+------------+----------+\n|Transmission|wheelerkey|\n+------------+----------+\n|   Automatic|         F|\n|      Manual|         F|\n+------------+----------+\n\nsuccess\n"
     ]
    }
   ],
   "source": [
    "#nnnn\n",
    "from pyspark.sql.functions import col, input_file_name, lit, when, split, regexp_replace\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# stg_df_1 = spark.read.format('parquet').option('Header', 'True').option('inferSchema', 'True').load(parquet_file_path1) \\\n",
    "#     .withColumn('inputfilename', input_file_name()).withColumn('inputfilename', split(F.col('inputfilename'), '/').getItem(2)).withColumn('WheelerKey', when(F.col('inputfilename') == '2-WheelSales', lit('T')).otherwise(lit('F'))).select(F.col('brand').alias('BrandName'), F.col('WheelerKey'))\n",
    "\n",
    "\n",
    "combined_stg =  spark.read.format('parquet').option('Header', 'True').option('inferSchema', 'True').load(parquet_file_path2) \\\n",
    "    .withColumn('inputfilename', input_file_name()).withColumn('inputfilename', split(col('inputfilename'), '/').getItem(2)).withColumn('WheelerKey', when(F.col('inputfilename') == '4-WheelSales', lit('T')).otherwise(lit('F'))).select(col('transmission').alias('Transmission'), 'wheelerkey')\n",
    "\n",
    "# combined_stg = stg_df_1.unionByName(stg_df_2)\n",
    "print(\"combined_count :\", combined_stg.count())\n",
    "\n",
    "print(\"combined_distinct :\" ,combined_stg.count())\n",
    "combined_stg.show()\n",
    "\n",
    "dim_df = spark.sql(\"\"\"SELECT * FROM  dev.dimtransmission\"\"\")\n",
    "print('dim_df show...')\n",
    "dim_df.show()\n",
    "print(\"check for new records...\")\n",
    "\n",
    "new_records = combined_stg.join(dim_df, 'Transmission', 'left_anti')\n",
    "new_records.show()\n",
    "\n",
    "updated_records = combined_stg.join(dim_df, combined_stg['Transmission'] == dim_df['Transmission'], 'inner').select(dim_df['*'])\n",
    "\n",
    "print(\"matching from src to target \")\n",
    "updated_records.show()\n",
    "\n",
    "combined_records = new_records.unionByName(updated_records.drop('pkTransmissionId'))\n",
    "\n",
    "print('combined....')\n",
    "combined_records = combined_records.dropDuplicates(['Transmission', 'WheelerKey'])\n",
    "print('combined_records df count:', combined_records.count())\n",
    "combined_records.show()\n",
    "\n",
    "combined_records.write.mode('overwrite').saveAsTable(\"dev.dimtransmission\")\n",
    "\n",
    "print(\"success\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14e5dff5-ae09-48a2-bdc0-5d6100326fb2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>pkTransmissionId</th><th>Transmission</th><th>WheelerKey</th></tr></thead><tbody><tr><td>1</td><td>Automatic</td><td>F</td></tr><tr><td>2</td><td>Manual</td><td>F</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Automatic",
         "F"
        ],
        [
         2,
         "Manual",
         "F"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "pkTransmissionId",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Transmission",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "WheelerKey",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from dev.dimtransmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6949baff-b62a-4fe4-b029-b0fe138ff7d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "truncate table dev.dimtransmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84c4a7cb-cfe4-4385-ba87-4d939ff0708f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n|transmission|\n+------------+\n|   Automatic|\n|      Manual|\n+------------+\n\n"
     ]
    }
   ],
   "source": [
    "# distinct_transmission = df2.select(\"transmission\").distinct()\n",
    "# distinct_transmission.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "689a9de2-7809-48ac-947e-234087b1adee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime \n",
    "\n",
    "def transmission_scd1(path):\n",
    "    stg_df = spark.read.format('parquet') \\\n",
    "                    .option('Header', 'True') \\\n",
    "                    .load(path) \\\n",
    "                    .withColumn('inputfilename', input_file_name()) \\\n",
    "                    .withColumn('inputfilename',  concat_ws(\"/\", expr(\"slice(split(inputfilename, '/'), 1, 3)\"))) \\\n",
    "                    .withColumn('wheelerkey', when(col('inputfilename') == 'dbfs:/Silver/4_wheelers', lit('F')).otherwise(lit('T'))) \\\n",
    "                    .select(col('transmission').alias('Transmission'), 'wheelerkey').distinct()\n",
    "\n",
    "    print(\"read the table\")\n",
    "\n",
    "    dim_df = spark.sql(\"select * from dev.dimtransmission\")\n",
    "\n",
    "    # dim_df.show()\n",
    "    print(\"check for new and updated records...\")\n",
    "    new_records = stg_df.join(dim_df, 'Transmission', 'left_anti')\n",
    "    new_records.show()\n",
    "\n",
    "    print(\"check for matched records\")\n",
    "\n",
    "    matched_records = stg_df.join(dim_df,  stg_df['Transmission']==dim_df['Transmission'], 'inner').select(dim_df['*'])\n",
    "\n",
    "    matched_records.show()\n",
    "\n",
    "    print(\"final_df\")\n",
    "\n",
    "    final_df = matched_records.drop('pkTransmissionId').unionByName(new_records)\n",
    "\n",
    "    final_df.show()\n",
    "\n",
    "    final_df.write.mode('overwrite').saveAsTable('dev.dimtransmission')\n",
    "\n",
    "    print('success')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fad34ed5-8734-491c-b09b-aa2b621c5e8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read the table\ncheck for new and updated records...\n+------------+----------+\n|Transmission|wheelerkey|\n+------------+----------+\n|   Automatic|         F|\n|      Manual|         F|\n+------------+----------+\n\ncheck for matched records\n+----------------+------------+----------+\n|pkTransmissionId|Transmission|WheelerKey|\n+----------------+------------+----------+\n+----------------+------------+----------+\n\nfinal_df\n+------------+----------+\n|Transmission|WheelerKey|\n+------------+----------+\n|   Automatic|         F|\n|      Manual|         F|\n+------------+----------+\n\nsuccess\n"
     ]
    }
   ],
   "source": [
    "transmission_scd1(parquet_file_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ca032b8-b1a4-4294-8067-40d547dc3e24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>pkTransmissionId</th><th>Transmission</th><th>WheelerKey</th></tr></thead><tbody><tr><td>1</td><td>Automatic</td><td>F</td></tr><tr><td>2</td><td>Manual</td><td>F</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Automatic",
         "F"
        ],
        [
         2,
         "Manual",
         "F"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "pkTransmissionId",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Transmission",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "WheelerKey",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from dev.dimtransmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfab5bd3-3fca-4479-8263-2a08b153837f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from delta.tables import *\n",
    "# from pyspark.sql.functions import lit\n",
    "# delta_df=DeltaTable.forPath(spark, \"dbfs:/delta_tables/Dim6\")\n",
    "\n",
    "# delta_df.alias('target').merge(\n",
    "#     source=df2.select('transmission').distinct().alias('source'),\n",
    "#     condition='target.Transmission=source.transmission'\n",
    "# ).whenMatchedUpdate(\n",
    "#     set={\n",
    "#         'WheelerKey': lit('F')\n",
    "#     }\n",
    "# ).whenNotMatchedInsert(\n",
    "#     values={\n",
    "#         'Transmission': 'source.transmission',\n",
    "#         'WheelerKey': lit('F')\n",
    "#     }\n",
    "# ).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82fa8b56-879f-4b84-bce3-a38c034fc36e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 336972736029717,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "nb_DimTransmission",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
